# -*- coding: utf-8 -*-
"""Training andd Testing Document.ipynb

Automatically generated by Colaboratory.

from google.colab import drive
drive.mount('/content/drive')

import joblib
import numpy as np
import pandas as pd
import sklearn
from sklearn import mixture
from keras.engine import Layer 
import os
import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow import clip_by_global_norm
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.initializers import lecun_normal
from tensorflow.keras.optimizers import Adam,SGD
from tensorflow.keras.losses import binary_crossentropy,MAE,MSE,CategoricalCrossentropy
from tensorflow.keras import layers as lyrs
from tensorflow.keras.layers import Attention,UpSampling1D,Conv1DTranspose,GRU,LSTM,Conv1D,Bidirectional,Dense,Input,RepeatVector,Reshape,Flatten,AveragePooling1D,GlobalAvgPool1D,GlobalMaxPool1D,Lambda,AlphaDropout,TimeDistributed,Embedding,Activation,BatchNormalization,LayerNormalization,Dropout,AlphaDropout
from tensorflow import keras
from tensorflow.keras import Model
from tensorflow.keras.layers import Concatenate as concat
import tensorflow.keras.backend as back
from tensorflow.keras.metrics import BinaryAccuracy
from tensorflow.math import reduce_logsumexp, reduce_mean, reduce_sum
from tensorflow.keras.backend import clip
from tensorflow.linalg import tensor_diag
from tensorflow.nn import softplus
from collections import Counter
import sklearn
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from time import time 
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.regularizers import l2

"""# **MAE Testing and Training**"""

selfies_data_path=str(input("Insert selfies_data_path: "))
x_train = np.load(selfies_data_path,allow_pickle=True)

latent_dim=84
mol_input_shape=(128)
mol_feat_num=84

mae_encoder,mae_decoder=build_MAE(latent_dim,mol_input_shape,mol_feat_num)

def build_MAE(latent_dim,mol_input_shape,mol_feat_num):
  mol_input=Input(shape=(mol_input_shape))
  lyr=Embedding(mol_feat_num+1,mol_feat_num,input_length=mol_input_shape,mask_zero=True)(mol_input)

  lyr=Bidirectional(GRU(240,return_sequences=True),merge_mode='concat')(lyr)
  lyr=LayerNormalization()(lyr)

  lyr=Bidirectional(GRU(240,return_sequences=True),merge_mode='concat')(lyr)
  lyr=LayerNormalization()(lyr)
  
  #--------------------latent---------------------------------

  lyr=GlobalMaxPool1D()(lyr)
  latent_vector=Dense(latent_dim,activation="linear")(lyr)

  mae_encoder=Model(mol_input,latent_vector,name="mae_encoder")
  mae_encoder.summary()

  #-------------------decoder-------------------------------

  input=Input(shape=(latent_dim,))
  lyr=RepeatVector(mol_input_shape)(input)

  lyr=Reshape((mol_input_shape,latent_dim))(lyr)

  lyr=GRU(240*2,return_sequences=True,kernel_regularizer=l2(0.01))(lyr)
  lyr=LayerNormalization()(lyr)

  lyr=GRU(240*2,return_sequences=True,kernel_regularizer=l2(0.01))(lyr)
  lyr=LayerNormalization()(lyr)

  output=TimeDistributed(Dense(mol_feat_num+1, activation='softmax'))(lyr)
  mae_decoder=Model(input,output,name="mae_decoder")

  mae_decoder.summary()
  return mae_encoder,mae_decoder

mae_recon_loss=tf.keras.losses.SparseCategoricalCrossentropy()

def mae_reg_loss(latent_sample):
  return reduce_mean(back.square(latent_sample))/4

class MAE(Model):
  def __init__(self,mae_encoder,mae_decoder,latent_dim):
    
    super(MAE,self).__init__()

    self.mae_encoder=mae_encoder
    self.mae_decoder=mae_decoder

    self.latent_dim=latent_dim

  def compile(self,mae_optimizer,
              mae_recon_loss,mae_reg_loss):
    super().compile()

    self.mae_optimizer=mae_optimizer

    self.mae_recon_loss=mae_recon_loss
    self.mae_reg_loss=mae_reg_loss

  def train_step(self,x):

    batch_size=back.shape(x)[0]

    with tf.GradientTape() as tape:
      latent_sample=self.mae_encoder(x,training=True)
      reconstructed_x=self.mae_decoder(latent_sample,training=True)
      
      mae_recon_loss=128*self.mae_recon_loss(x,reconstructed_x)
      mae_reg_loss=self.mae_reg_loss(latent_sample)

      mae_loss=mae_recon_loss+mae_reg_loss
      
    mae_gradient=tape.gradient(mae_loss,(self.mae_encoder.trainable_variables+self.mae_decoder.trainable_variables))
    self.mae_optimizer.apply_gradients(zip(mae_gradient,(self.mae_encoder.trainable_variables+self.mae_decoder.trainable_variables)))

    return {
        "MAE_Reconstruction_Loss": mae_recon_loss,
        "MAE_Reg_loss": mae_reg_loss
            }

clipping_val=0.5
MAE_l2=MAE(mae_encoder,mae_decoder,latent_dim) 

mae_optimizer=Adam(learning_rate=0.0005,
                    beta_1=0.9,
                    beta_2=0.99,
                   clipvalue=clipping_val)

MAE_l2.compile(mae_optimizer,mae_recon_loss,mae_reg_loss)

encoder_path=str(input("Insert encoder_path: "))
decoder_path=str(input("Insert decoder_path: "))

MAE_l2.fit(x=x_train,batch_size=128,epochs=50,shuffle=True)
MAE_l2.mae_encoder.save_weights(encoder_path)
MAE_l2.mae_decoder.save_weights(decoder_path)

"""BGMM Training"""

latent_representations=MAE_l2.mae_encoder.predict(x_train,batch_size=1000)

latent_representations_path=str(input("Insert latent_representations_path: "))
latent_representations = np.load(latent_representations_path,allow_pickle=True)

bgmm_sampler=mixture.BayesianGaussianMixture(n_components=12,covariance_type='full',verbose=4,verbose_interval=5,warm_start=True)
bgmm_sampler.fit(latent_representations)

bgmm_sampler_path=str(input("Insert bgmm_sampler_path: "))
joblib.dump(bgmm_sampler,bgmm_sampler_path)
bgmm_sampler = joblib.load(bgmm_sampler_path)

labels=['','[C]',
 '[#C]',
 '[=C]',
 '[c]',
 '[=c]',
 '[-c]',
 '[N]',
 '[#N]',
 '[=N]',
 '[-n]',
 '[n]',
 '[N+expl]',
 '[=N+expl]',
 '[=N-expl]',
 '[NHexpl]',
 '[=NH2+expl]',
 '[O]',
 '[=O]',
 '[o]',
 '[Oexpl]',
 '[O-expl]',
 '[F]',
 '[P]',
 '[S]',
 '[=S]',
 '[s]',
 '[Cl]',
 '[Cl-expl]',
 '[Br]',
 '[Br-expl]',
 '[I]',
 '[I-expl]',
 '[nHexpl]',
 '[Hexpl]',
 '[epsilon]',
 '[Branch1_1]',
 '[Branch1_2]',
 '[Branch1_3]',
 '[Branch2_1]',
 '[Branch2_2]',
 '[Branch2_3]',
 '[Branch3_3]',
 '[Branch3_1]',
 '[Branch3_2]',
 '[Ring1]',
 '[Expl-Ring1]',
 '[Expl=Ring1]',
 '[Ring2]',
 '[Expl-Ring2]',
 '[Expl=Ring2]',
 '[Ring3]',
 '.',
 '[C@@Hexpl]',
 '[C@Hexpl]',
 '[C@expl]',
 '[C@@expl]',
 '[/C]',
 '[\\C]',
 '[/S]',
 '[Expl\\Ring1]',
 '[/N]',
 '[\\N]',
 '[/C@Hexpl]',
 '[H+expl]',
 '[S-expl]',
 '[Zn+2expl]',
 '[Siexpl]',
 '[Na+expl]',
 '[\\S]',
 '[/O]',
 '[P@expl]',
 '[Expl/Ring2]',
 '[N-expl]',
 '[B]',
 '[\\C@@Hexpl]',
 '[/C@@Hexpl]',
 '[=S+expl]',
 '[Cexpl]',
 '[=Cexpl]',
 '[/Br]',
 '[/Cexpl]',
 '[/Cl]',
 '[Znexpl]',
 '[P@@expl]']

def onehot_to_smiles(onehot):
  selfies_mol=""
  for i in range(128):
    selfies_mol+=mol_dict[np.argmax(onehot[0][i])]
  smiles=selfies.decoder(selfies_mol)

  return smiles

generated_mols=mae_decoder.predict(bgmm_sampler.sample(50000)[0],batch_size=500)
generated_smiles=np.empty([50000],dtype=object)
for i in range(50000):
  generated_smiles[i]=onehot_to_smiles(generated_mols[i])

novel_count=0
for i in range(len(x_train)):
  for j in range(50000):
    if generated_smiles[j]==x_train[i]:
      novel_count+=1
print("Novelty:",novel_count/50000)

!pip install moses

metrics = moses.get_all_metrics(list_of_generated_smiles)

"""
# **Deep ADTP Testing and Training**"""

def mish(x):
  return x*back.tanh(back.softplus(x))
  
from keras.utils.generic_utils import get_custom_objects
get_custom_objects().update({'mish': Activation(mish)})

def residual_block(lyr,filter_size,kernel_size,dilation=1,padding="same"):
  reslyr=lyr
  lyr=Conv1D(filter_size,kernel_size,activation="mish",padding=padding,dilation_rate=dilation)(lyr)
  lyr=BatchNormalization()(lyr)
  lyr=lyrs.Add()([lyr,reslyr])
  return lyr

drug_input_shape=(128)
target_input_shape=(1500)
#_________________Target_________________

target_input=Input(shape=target_input_shape)
target_embedding=Embedding(21,170,mask_zero=True)(target_input)
tlyr=residual_block(target_embedding,170,6,1,"causal")

tlyr=residual_block(tlyr,170,6,2,"causal")
tlyr=residual_block(tlyr,170,6,4,"causal")

tlyr=residual_block(tlyr,170,6,8,"causal")
tlyr=Conv1D(170,6,activation="mish",padding="causal",dilation_rate=16)(tlyr)
tlyr=BatchNormalization()(tlyr)

#_________________Drug_________________

drug_input=Input(shape=drug_input_shape)
drug_embedding=Embedding(85,170,mask_zero=True)(drug_input)
dlyr=residual_block(drug_embedding,170,3,1,"causal")

dlyr=residual_block(dlyr,170,3,2,"causal")
dlyr=residual_block(dlyr,170,3,4,"causal")

dlyr=residual_block(dlyr,170,3,8,"causal")
dlyr=Conv1D(170,3,activation="mish",padding="causal",dilation_rate=16)(dlyr)
dlyr=BatchNormalization()(dlyr)

#______________Predictor______________

att_dlyr=Attention()([dlyr, tlyr])
att_dlyr=GlobalMaxPool1D()(att_dlyr)

att_tlyr=Attention()([tlyr, dlyr])
att_tlyr=GlobalMaxPool1D()(att_tlyr)

lyr=concat()([att_dlyr,att_tlyr])

lyr=Dense(5*170,activation="mish")(lyr)
lyr=Dropout(0.1)(lyr)

lyr=Dense(5*170,activation="mish")(lyr)
lyr=Dropout(0.1)(lyr)

lyr=Dense(5*170,activation="mish")(lyr)
output=Dense(1,activation="linear")(lyr)

deep_adtp=Model([target_input,drug_input],output,name="Deep_ADTP")
deep_adtp.summary()

deep_adtp.compile(optimizer=Adam(learning_rate=0.0005),loss=["mean_squared_error"],metrics = ["mean_squared_error"])

kiba_selfies_path=str(input("Insert kiba_selfies_path: "))
kiba_selfies=np.load(kiba_selfies_path,allow_pickle=True)

kiba_proteins=np.load(kiba_proteins_path,allow_pickle=True)
kiba_proteins_path=str(input("Insert kiba_proteins_path: "))

kiba_bindaff_path=str(input("Insert kiba_bindaff_path: "))
kiba_bindaff=np.load(kiba_bindaff_path,allow_pickle=True)

deep_adtp.fit(x=[kiba_proteins,kiba_selfies],y=kiba_bindaff,batch_size=180,shuffle=True,epochs=100)

deep_adtp_weights_path=str(input("Insert deep_adtp_weights_path: "))
deep_adtp.save_weights(deep_adtp_weights_path)

deep_adtp.load_weights(deep_adtp_weights_path)

preds=deep_adtp.predict(x=[kiba_proteins,kiba_selfies],batch_size=500)

#Bu kodu Öztürk, H., Ozkirimli, E., & Özgür, A. (2018, June 5). 
#DeepDTA: Deep Drug-Target Binding Affinity Prediction. 
#arXiv.org. https://arxiv.org/abs/1801.10193. kağıdının github sayfasından aldık.
def concordance_index(Y, P):
    summ = 0
    pair = 0
    
    for i in range(1, len(Y)):
        for j in range(0, i):
            if i is not j:
                if(Y[i] > Y[j]):
                    pair +=1
                    summ +=  1* (P[i] > P[j]) + 0.5 * (P[i] == P[j])
    if pair is not 0:
        return summ/pair
    else:
        return 0

concordance_index(kiba_bindaff,preds)
